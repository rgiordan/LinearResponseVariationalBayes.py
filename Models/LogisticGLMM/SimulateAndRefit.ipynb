{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import VariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "import VariationalBayes.SparseObjectives as obj_lib\n",
    "import VariationalBayes.ExponentialFamilies as ef\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import autograd\n",
    "import autograd.numpy as np\n",
    "import scipy as sp\n",
    "from scipy import sparse\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                        'LinearResponseVariationalBayes.py/Models/LogisticGLMM/data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "\n",
    "true_beta = np.array(range(5))\n",
    "true_beta = true_beta - np.mean(true_beta)\n",
    "true_mu = 0.\n",
    "true_tau = 40.0\n",
    "\n",
    "# Used 2, 5, 10, 20, 40, 60, 100\n",
    "num_obs_per_group = 100\n",
    "analysis_name = 'simulated_data_for_refit_{}'.format(num_obs_per_group)\n",
    "\n",
    "true_params = logit_glmm.TrueParameters(\n",
    "    num_obs_per_group = num_obs_per_group,\n",
    "    num_groups = 200,\n",
    "    true_beta = true_beta,\n",
    "    true_mu = 0.,\n",
    "    true_tau = 40.0)\n",
    "\n",
    "x_mat, y_g_vec, y_vec  = true_params.generate_data()\n",
    "prior_par = logit_glmm.get_default_prior_params(true_params.beta_dim)\n",
    "glmm_par = logit_glmm.get_glmm_parameters(K=true_params.beta_dim, NG=true_params.num_groups)\n",
    "logit_glmm.initialize_glmm_pars(glmm_par)\n",
    "init_par_vec = glmm_par.get_free()\n",
    "\n",
    "timer = obj_lib.Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0  value:  16893.9343295\n",
      "Iter  5  value:  12268.4119005\n",
      "Iter  10  value:  12045.771868\n",
      "Iter  15  value:  12045.763536\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 12045.763536\n",
      "         Iterations: 16\n",
      "         Function evaluations: 17\n",
      "         Gradient evaluations: 17\n",
      "         Hessian evaluations: 0\n",
      "Group 0 of 199.\n",
      "Group 20 of 199.\n",
      "Group 40 of 199.\n",
      "Group 60 of 199.\n",
      "Group 80 of 199.\n",
      "Group 100 of 199.\n",
      "Group 120 of 199.\n",
      "Group 140 of 199.\n",
      "Group 160 of 199.\n",
      "Group 180 of 199.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0 of 199\n",
      "Group 50 of 199\n",
      "Group 100 of 199\n",
      "Group 150 of 199\n",
      "Derivatives: 21.6134934425354 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get an initial fit and preconditioner.\n",
    "\n",
    "model = logit_glmm.LogisticGLMM(\n",
    "    glmm_par=glmm_par, prior_par=prior_par, x_mat=x_mat,\n",
    "    y_vec=y_vec, y_g_vec=y_g_vec, num_gh_points=5)\n",
    "\n",
    "vb_time = time.time()\n",
    "vb_opt = model.tr_optimize(init_par_vec, gtol=1e-6, maxiter=500)\n",
    "opt_x = vb_opt.x\n",
    "\n",
    "timer.tic()\n",
    "kl_hess = model.get_sparse_free_hessian(opt_x, print_every_n=20)\n",
    "weight_jac = model.get_sparse_weight_free_jacobian(opt_x, print_every_n=50)\n",
    "moment_jac = model.moment_wrapper.get_moment_jacobian(opt_x)\n",
    "timer.toc('Derivatives')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/scipy/sparse/linalg/dsolve/linsolve.py:102: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "preconditioner = sp.sparse.diags([1 / np.sqrt(kl_hess.diagonal())], [0])\n",
    "model.objective.preconditioner = preconditioner\n",
    "cond_init = sp.sparse.linalg.spsolve(preconditioner, opt_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_and_fit(refit_model, cond_init, true_params):\n",
    "    x_mat, y_g_vec, y_vec = \\\n",
    "        true_params.generate_data()\n",
    "    refit_model.x_mat = x_mat\n",
    "    refit_model.y_vec = y_vec\n",
    "    refit_model.y_g_vec = y_g_vec\n",
    "    #print('x mat: ', x_mat[0, 0], refit_model.x_mat[0, 0])\n",
    "\n",
    "    vb_time = time.time()\n",
    "    vb_opt = refit_model.tr_optimize_cond(\n",
    "        cond_init,\n",
    "        preconditioner=preconditioner,\n",
    "        gtol=1e-6, maxiter=500, verbose=False)\n",
    "    return vb_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim 0 of 199\n",
      "Sim 20 of 199\n",
      "Sim 40 of 199\n",
      "Sim 60 of 199\n",
      "Sim 80 of 199\n",
      "Sim 100 of 199\n",
      "Sim 120 of 199\n",
      "Sim 140 of 199\n",
      "Sim 160 of 199\n",
      "Sim 180 of 199\n",
      "Simulations: 628.6379897594452 seconds\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "opt_x_sims = []\n",
    "num_sims = 200\n",
    "timer.tic()\n",
    "for sim in range(num_sims):\n",
    "    if sim % 20 == 0:\n",
    "        print('Sim {} of {}'.format(sim, num_sims - 1))\n",
    "    this_vb_opt = simulate_and_fit(model, cond_init, true_params)\n",
    "    assert(this_vb_opt.success == 1 or \\\n",
    "           this_vb_opt.message == 'A bad approximation caused failure to predict improvement.')\n",
    "    #print(this_vb_opt.message)\n",
    "    this_opt_x = model.objective.uncondition_x(this_vb_opt.x)\n",
    "    #print('This opt x:', this_opt_x[0:2])\n",
    "    \n",
    "    opt_x_sims.append(copy.deepcopy(this_opt_x))\n",
    "timer.toc('Simulations')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "{'Derivatives': 21.6134934425354, 'Simulations': 628.6379897594452}\n"
     ]
    }
   ],
   "source": [
    "print(this_vb_opt.message)\n",
    "print(timer.time_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/LinearResponseVariationalBayes.py/Models/LogisticGLMM/data/simulated_data_for_refit_100_python_refit_jackknife_results.pkl\n",
      "\n",
      "\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "# Write the result to a pickle file for use in R.\n",
    "\n",
    "run_name = 'simulation'\n",
    "\n",
    "pickle_output_filename = os.path.join(data_dir, '%s_python_refit_jackknife_results.pkl' % analysis_name)\n",
    "pickle_output = open(pickle_output_filename, 'wb')\n",
    "\n",
    "# Note that it does not seem that you can pickle a sparse Cholesky decomposition.\n",
    "model.glmm_par.set_free(opt_x)\n",
    "pickle_result_dict = logit_glmm.get_pickle_dictionary(model, kl_hess, moment_jac)\n",
    "pickle_result_dict.update({\n",
    "    'true_params': true_params,\n",
    "    'glmm_par_sims': opt_x_sims,\n",
    "    'weight_jac': obj_lib.pack_csr_matrix(weight_jac) \n",
    "  })\n",
    "\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(pickle_result_dict, pickle_output)\n",
    "pickle_output.close()\n",
    "\n",
    "print(pickle_output_filename)\n",
    "\n",
    "print('\\n\\nDONE.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
