{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import LinearResponseVariationalBayes as vb\n",
    "import LinearResponseVariationalBayes.SparseObjectives as obj_lib\n",
    "import LinearResponseVariationalBayes.OptimizationUtils as opt_lib\n",
    "import autograd.numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dummy_np_test(object):\n",
    "    def __init__(sefl):\n",
    "        pass\n",
    "    def assert_array_almost_equal(self, x, y):\n",
    "        assert np.linalg.norm(x - y) < 1e-6\n",
    "\n",
    "np_test = dummy_np_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticModel(object):\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "        self.param = vb.VectorParam('theta', size=dim)\n",
    "\n",
    "        vec = np.linspace(0.1, 0.3, num=dim)\n",
    "        self.matrix = np.outer(vec, vec) + np.eye(dim)\n",
    "        self.vec = vec\n",
    "\n",
    "        self.objective = obj_lib.Objective(self.param, self.get_objective)\n",
    "\n",
    "    def get_objective(self):\n",
    "        theta = self.param.get()\n",
    "        objective = 0.5 * theta.T @ self.matrix @ theta + self.vec @ theta\n",
    "        return objective\n",
    "\n",
    "    # Testing functions that use the fact that the optimum has a closed form.\n",
    "    def get_true_optimum_theta(self):\n",
    "        theta = -1 * np.linalg.solve(self.matrix, self.vec)\n",
    "        return theta\n",
    "\n",
    "    def get_true_optimum(self):\n",
    "        # ...in the free parameterization.\n",
    "        theta = self.get_true_optimum_theta()\n",
    "        self.param.set_vector(theta)\n",
    "        return self.param.get_free()\n",
    "    \n",
    "model = QuadraticModel(3)\n",
    "\n",
    "init_x = np.zeros(model.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0  value:  0.0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.061404\n",
      "         Iterations: 2\n",
      "         Function evaluations: 3\n",
      "         Gradient evaluations: 3\n",
      "Iter  0  value:  0.0\n",
      "Iter  1  value:  -0.06140350877192982\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.061404\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 0\n"
     ]
    }
   ],
   "source": [
    "opt_x, opt_result = opt_lib.minimize_objective_bfgs(model.objective, init_x, precondition=False)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_result.x)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_x)\n",
    "\n",
    "opt_x, opt_result = opt_lib.minimize_objective_trust_ncg(model.objective, init_x, precondition=False)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_result.x)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian, inv_hess_sqrt, hessian_corrected = \\\n",
    "    opt_lib.set_objective_preconditioner(model.objective, init_x)\n",
    "np_test.assert_array_almost_equal(model.matrix, hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0  value:  0.0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.061404\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "Iter  0  value:  0.0\n",
      "Iter  1  value:  -0.061403508771929835\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.061404\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 0\n"
     ]
    }
   ],
   "source": [
    "opt_x, opt_result = opt_lib.minimize_objective_bfgs(model.objective, init_x, precondition=True)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_x)\n",
    "\n",
    "opt_x, opt_result = opt_lib.minimize_objective_trust_ncg(model.objective, init_x, precondition=True)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7604516071836537e-05\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8239a0f51baa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_true_optimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mnp_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_array_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_true_optimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-94b546273328>\u001b[0m in \u001b[0;36massert_array_almost_equal\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massert_array_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnp_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_np_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def initial_optimization(x):\n",
    "    new_x = np.random.random(len(x))\n",
    "    return new_x, new_x\n",
    "\n",
    "def take_gradient_step(x):\n",
    "    grad = model.objective.fun_free_grad(x)\n",
    "    return x - 0.5 * grad, x\n",
    "\n",
    "opt_x, converged, x_conv, f_conv, grad_conv, obj_opt, opt_results = \\\n",
    "    opt_lib.repeatedly_optimize(\n",
    "        model.objective,\n",
    "        take_gradient_step,\n",
    "        init_x,\n",
    "        initial_optimization_fun=initial_optimization,\n",
    "        keep_intermediate_optimizations=True,\n",
    "        max_iter=100)\n",
    "    \n",
    "print(np.linalg.norm(opt_x - model.get_true_optimum()))\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
