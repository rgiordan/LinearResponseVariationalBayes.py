{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import LinearResponseVariationalBayes as vb\n",
    "import LinearResponseVariationalBayes.SparseObjectives as obj_lib\n",
    "import LinearResponseVariationalBayes.OptimizationUtils as opt_lib\n",
    "import autograd.numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dummy_np_test(object):\n",
    "    def __init__(sefl):\n",
    "        pass\n",
    "    def assert_array_almost_equal(self, x, y):\n",
    "        assert np.linalg.norm(x - y) < 1e-6\n",
    "\n",
    "np_test = dummy_np_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticModel(object):\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "        self.param = vb.VectorParam('theta', size=dim)\n",
    "\n",
    "        vec = np.linspace(0.1, 0.3, num=dim)\n",
    "        self.matrix = np.outer(vec, vec) + np.eye(dim)\n",
    "        self.vec = vec\n",
    "\n",
    "        self.objective = obj_lib.Objective(self.param, self.get_objective)\n",
    "\n",
    "    def get_objective(self):\n",
    "        theta = self.param.get()\n",
    "        objective = 0.5 * theta.T @ self.matrix @ theta + self.vec @ theta\n",
    "        return objective\n",
    "\n",
    "    # Testing functions that use the fact that the optimum has a closed form.\n",
    "    def get_true_optimum_theta(self):\n",
    "        theta = -1 * np.linalg.solve(self.matrix, self.vec)\n",
    "        return theta\n",
    "\n",
    "    def get_true_optimum(self):\n",
    "        # ...in the free parameterization.\n",
    "        theta = self.get_true_optimum_theta()\n",
    "        self.param.set_vector(theta)\n",
    "        return self.param.get_free()\n",
    "    \n",
    "model = QuadraticModel(3)\n",
    "\n",
    "init_x = np.zeros(model.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0  value:  0.0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.061404\n",
      "         Iterations: 2\n",
      "         Function evaluations: 3\n",
      "         Gradient evaluations: 3\n",
      "Iter  0  value:  0.0\n",
      "Iter  1  value:  -0.06140350877192982\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.061404\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 0\n"
     ]
    }
   ],
   "source": [
    "opt_x, opt_result = opt_lib.minimize_objective_bfgs(model.objective, init_x, precondition=False)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_result.x)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_x)\n",
    "\n",
    "opt_x, opt_result = opt_lib.minimize_objective_trust_ncg(model.objective, init_x, precondition=False)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_result.x)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian, inv_hess_sqrt, hessian_corrected = \\\n",
    "    opt_lib.set_objective_preconditioner(model.objective, init_x)\n",
    "np_test.assert_array_almost_equal(model.matrix, hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0  value:  0.0\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.061404\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "Iter  0  value:  0.0\n",
      "Iter  1  value:  -0.061403508771929835\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.061404\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "         Hessian evaluations: 0\n"
     ]
    }
   ],
   "source": [
    "opt_x, opt_result = opt_lib.minimize_objective_bfgs(model.objective, init_x, precondition=True)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_x)\n",
    "\n",
    "opt_x, opt_result = opt_lib.minimize_objective_trust_ncg(model.objective, init_x, precondition=True)\n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_optimization(x):\n",
    "    new_x = np.random.random(len(x))\n",
    "    return new_x, new_x\n",
    "\n",
    "def take_gradient_step(x):\n",
    "    grad = model.objective.fun_free_grad(x)\n",
    "    return x - 0.1 * grad, x\n",
    "\n",
    "new_x, converged, x_conv, f_conv, grad_conv, obj_opt, opt_results = \\\n",
    "    opt_lib.repeatedly_optimize(\n",
    "        model.objective,\n",
    "        take_gradient_step,\n",
    "        init_x,\n",
    "        initial_optimization_fun=initial_optimization,\n",
    "        keep_intermediate_optimizations=True)\n",
    "    \n",
    "np_test.assert_array_almost_equal(model.get_true_optimum(), opt_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
